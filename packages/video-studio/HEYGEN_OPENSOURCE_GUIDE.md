# üé¨ HEYGEN OPEN SOURCE - Documentation Compl√®te

> **Version**: 1.0.0 | **Derni√®re mise √† jour**: D√©cembre 2025  
> **Optimis√© pour**: Minisforum M1 Pro-285H (Intel Core Ultra)

## üìã Table des Mati√®res

1. [Introduction](#introduction)
2. [Outils Open-Source Int√©gr√©s](#outils-open-source-int√©gr√©s)
3. [Installation Rapide](#installation-rapide)
4. [Configuration OpenVINO (Intel)](#configuration-openvino-intel)
5. [Utilisation](#utilisation)
6. [API Reference](#api-reference)
7. [Troubleshooting](#troubleshooting)

---

## Introduction

Ce projet fournit une alternative 100% open-source √† HeyGen pour cr√©er des vid√©os d'avatars parlants. Il combine plusieurs technologies de pointe pour:

- üé≠ **Animer des images statiques** avec synchronisation labiale
- üó£Ô∏è **G√©n√©rer des voix naturelles** avec Edge-TTS (gratuit)
- üñºÔ∏è **Cr√©er des illustrations** avec IA
- üé¨ **Monter des vid√©os** automatiquement

---

## Outils Open-Source Int√©gr√©s

### üèÜ Tier 1: Meilleure Qualit√©

| Outil | GitHub | Description | Performance |
|-------|--------|-------------|-------------|
| **SadTalker** | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | Animation 3D r√©aliste de portraits | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **MuseTalk** | [TMElyralab/MuseTalk](https://github.com/TMElyralab/MuseTalk) | Lip-sync temps r√©el 30+ FPS | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **LatentSync** | [bytedance/LatentSync](https://github.com/bytedance/LatentSync) | Lip-sync haute r√©solution (ByteDance) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

### ü•à Tier 2: Bonne Qualit√© / Rapide

| Outil | GitHub | Description | Performance |
|-------|--------|-------------|-------------|
| **Wav2Lip** | [Rudrabha/Wav2Lip](https://github.com/Rudrabha/Wav2Lip) | Lip-sync classique et fiable | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Wav2Lip-HD** | [saifhassan/Wav2Lip-HQ](https://github.com/Markfryazino/wav2lip-HD) | Wav2Lip + GFPGAN haute qualit√© | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **EchoMimic** | [BadToBest/EchoMimic](https://github.com/BadToBest/EchoMimic) | Audio + landmarks pour stabilit√© | ‚≠ê‚≠ê‚≠ê‚≠ê |

### ‚ö° Tier 3: Optimis√© Intel / OpenVINO

| Outil | GitHub | Description | Performance |
|-------|--------|-------------|-------------|
| **RealtimeWav2lip** | [devkrish23/realtimeWav2lip](https://github.com/devkrish23/realtimeWav2lip) | Wav2Lip optimis√© OpenVINO | ‚ö°‚ö°‚ö°‚ö°‚ö° |
| **OpenVINO Notebooks** | [openvinotoolkit/openvino_notebooks](https://github.com/openvinotoolkit/openvino_notebooks) | Exemples d'optimisation | üìö |

---

## Installation Rapide

### Pr√©requis

```bash
# Python 3.10+
python --version

# FFmpeg
scoop install ffmpeg  # Windows
# ou: brew install ffmpeg  # macOS
# ou: apt install ffmpeg  # Linux
```

### 1Ô∏è‚É£ D√©pendances Python de Base

```bash
pip install edge-tts httpx replicate ffmpeg-python pillow
```

### 2Ô∏è‚É£ Installation SadTalker (Recommand√©)

```bash
# Cloner le repo
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker

# Cr√©er l'environnement
conda create -n sadtalker python=3.8
conda activate sadtalker

# Installer PyTorch + CUDA
pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113

# D√©pendances
pip install -r requirements.txt

# T√©l√©charger les mod√®les (automatique)
python download_models.py
```

**Mod√®les √† t√©l√©charger manuellement si n√©cessaire:**
- `checkpoints/` depuis [Releases](https://github.com/OpenTalker/SadTalker/releases)
- GFPGAN depuis [TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)

### 3Ô∏è‚É£ Installation MuseTalk (Temps R√©el)

```bash
# Cloner le repo
git clone https://github.com/TMElyralab/MuseTalk.git
cd MuseTalk

# Cr√©er l'environnement
conda create -n musetalk python=3.10
conda activate musetalk

# PyTorch 2.0.1
pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118

# D√©pendances
pip install -r requirements.txt

# MMLab packages
pip install --no-cache-dir -U openmim
mim install mmengine
mim install "mmcv==2.0.1"
mim install "mmdet==3.1.0"
mim install "mmpose==1.1.0"

# T√©l√©charger les mod√®les
huggingface-cli download TMElyralab/MuseTalk --local-dir ./models
```

### 4Ô∏è‚É£ Installation Wav2Lip Classique

```bash
git clone https://github.com/Rudrabha/Wav2Lip.git
cd Wav2Lip

pip install -r requirements.txt
pip install face_alignment

# T√©l√©charger le mod√®le wav2lip_gan.pth
# Depuis: https://github.com/Rudrabha/Wav2Lip#getting-the-weights
```

---

## Configuration OpenVINO (Intel)

**Optimis√© pour Minisforum M1 Pro-285H avec Intel Core Ultra 285H**

### Installation OpenVINO

```bash
pip install openvino openvino-dev[pytorch] nncf

# V√©rifier l'installation
python -c "from openvino import Core; print(Core().available_devices)"
# Devrait afficher: ['CPU', 'GPU', 'NPU']  # NPU si Core Ultra
```

### Wav2Lip OpenVINO

```bash
# Cloner la version OpenVINO
git clone https://github.com/devkrish23/realtimeWav2lip.git
cd realtimeWav2lip

pip install -r requirements.txt

# Convertir le mod√®le en format OpenVINO IR
python convert_to_openvino.py
```

### Configuration de l'Acc√©l√©rateur

```python
from avatar_video_generator import AvatarConfig, AvatarEngine

config = AvatarConfig(
    engine=AvatarEngine.WAV2LIP_OPENVINO,
    openvino_device="AUTO",  # AUTO, CPU, GPU, NPU
    openvino_precision="FP16",  # FP32, FP16, INT8
)
```

**Devices disponibles sur Core Ultra:**
- `CPU` - Intel Core Ultra (multi-thread)
- `GPU` - Intel Arc Graphics int√©gr√©
- `NPU` - Neural Processing Unit (le plus rapide pour l'IA)

---

## Utilisation

### Script Simple

```python
import asyncio
from heygen_opensource import HeyGenOpenSource, VideoConfig

async def main():
    # Configuration
    config = VideoConfig(
        voice="fr-FR-VivienneMultilingualNeural",
        use_real_photo=True,
    )
    
    # Cr√©er le producteur
    producer = HeyGenOpenSource(config)
    
    # Produire une vid√©o
    video_path = await producer.produce_video(
        topic="5 astuces IA que vous devez conna√Ætre",
        avatar_style="professional_woman"
    )
    
    print(f"Vid√©o cr√©√©e: {video_path}")

asyncio.run(main())
```

### Utilisation Directe du G√©n√©rateur d'Avatar

```python
from backend.services.avatar_video_generator import AvatarVideoGenerator, AvatarEngine

async def animate_portrait():
    generator = AvatarVideoGenerator()
    
    # G√©n√©rer l'audio
    audio = await generator.generate_tts_audio(
        "Bonjour, je suis votre avatar parlant!",
        "speech.mp3"
    )
    
    # Animer le portrait
    video = await generator.generate(
        image_path="portrait.jpg",
        audio_path="speech.mp3",
        output_path="output.mp4",
        engine=AvatarEngine.SADTALKER
    )
    
    return video
```

### Production en Batch

```python
async def batch_production():
    producer = HeyGenOpenSource()
    
    topics = [
        {"id": 1, "title": "L'IA en 2025"},
        {"id": 2, "title": "Bitcoin expliqu√©"},
        {"id": 3, "title": "Productivit√© maximale"},
    ]
    
    videos = await producer.batch_produce(topics, start_id=1)
    print(f"Produites: {len(videos)} vid√©os")
```

---

## API Reference

### AvatarEngine (Enum)

| Valeur | Description |
|--------|-------------|
| `SADTALKER` | SadTalker local |
| `MUSETALK` | MuseTalk local (temps r√©el) |
| `WAV2LIP` | Wav2Lip standard |
| `WAV2LIP_OPENVINO` | Wav2Lip optimis√© Intel |
| `ECHOMIMIC` | EchoMimic (audio + landmarks) |
| `LATENTSYNC` | LatentSync (ByteDance) |
| `REPLICATE_SADTALKER` | SadTalker cloud (fallback) |

### AvatarConfig

```python
@dataclass
class AvatarConfig:
    engine: AvatarEngine = AvatarEngine.SADTALKER
    models_dir: Path = Path("D:/AI_Models/avatar")
    resolution: tuple = (512, 512)
    fps: int = 25
    use_enhancer: bool = True  # GFPGAN
    
    # SadTalker
    preprocess: str = "crop"
    still_mode: bool = True
    expression_scale: float = 1.0
    
    # MuseTalk
    musetalk_bbox_shift: int = 0
    musetalk_use_float16: bool = True
    
    # OpenVINO
    openvino_device: str = "AUTO"
    openvino_precision: str = "FP16"
    
    # TTS
    tts_voice: str = "fr-FR-VivienneMultilingualNeural"
    tts_rate: str = "-5%"
```

### AvatarVideoGenerator Methods

| M√©thode | Description |
|---------|-------------|
| `generate(image, audio, output, engine)` | G√©n√®re une vid√©o d'avatar |
| `generate_tts_audio(text, output, voice)` | G√©n√®re l'audio TTS |
| `enhance_video(video, output)` | Am√©liore la qualit√© du visage |
| `install_engine(engine)` | Installe un moteur automatiquement |
| `get_status()` | Retourne l'√©tat de tous les moteurs |

---

## Troubleshooting

### ‚ùå "CUDA out of memory"

```bash
# R√©duire la r√©solution
config.resolution = (256, 256)

# Ou utiliser CPU/OpenVINO
config.engine = AvatarEngine.WAV2LIP_OPENVINO
```

### ‚ùå "Model not found"

```bash
# V√©rifier le chemin des mod√®les
ls D:/AI_Models/avatar/SadTalker/checkpoints/

# T√©l√©charger manuellement
cd SadTalker
python download_models.py
```

### ‚ùå "FFmpeg not found"

```bash
# Windows
scoop install ffmpeg
# OU
choco install ffmpeg

# V√©rifier
ffmpeg -version
```

### ‚ùå "OpenVINO device not available"

```python
# Lister les devices disponibles
from openvino import Core
core = Core()
print(core.available_devices)

# Utiliser CPU si GPU/NPU non disponible
config.openvino_device = "CPU"
```

### ‚ùå "Edge-TTS timeout"

```bash
# R√©installer edge-tts
pip uninstall edge-tts
pip install edge-tts --upgrade

# Tester
edge-tts --voice "fr-FR-VivienneMultilingualNeural" --text "Test" --write-media test.mp3
```

---

## üìö Ressources Additionnelles

### Documentation Officielle

- [SadTalker Paper](https://arxiv.org/abs/2211.12194) - CVPR 2023
- [MuseTalk Paper](https://arxiv.org/abs/2404.02037) - Tencent
- [Wav2Lip Paper](https://arxiv.org/abs/2008.10010) - ACM MM 2020
- [OpenVINO Documentation](https://docs.openvino.ai/)

### Tutoriels Vid√©o

- [SadTalker Tutorial (EN)](https://www.youtube.com/watch?v=9XN_36kNDJM)
- [MuseTalk Setup Guide](https://www.youtube.com/watch?v=example)
- [OpenVINO Optimization](https://www.youtube.com/watch?v=example)

### Communaut√©

- [SadTalker Discord](https://discord.gg/sadtalker)
- [OpenVINO Forum](https://community.intel.com/t5/OpenVINO)
- [HuggingFace Spaces](https://huggingface.co/spaces)

---

## üéØ Prochaines √âtapes

1. [ ] Int√©gration LivePortrait pour animations plus naturelles
2. [ ] Support multi-langues automatique
3. [ ] Interface WebUI (Gradio)
4. [ ] Pipeline de production YouTube automatis√©
5. [ ] Optimisation NPU pour Core Ultra

---

**Cr√©√© avec ‚ù§Ô∏è pour le projet WikiAsk**

*Derni√®re mise √† jour: D√©cembre 2025*
